{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXol5eu5-x5u"
   },
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mYIQcuxb35nP"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_cPhrPV-06-"
   },
   "source": [
    "# Dataset\n",
    "Load the dataset and print the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOgsW_Q06IqN",
    "outputId": "688cf7ec-89d1-4f73-d07b-a6d55f5e77ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Load the Reuters dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "classes = list(newsgroups_train.target_names)\n",
    "pprint(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsSHpQcg-6Uf"
   },
   "source": [
    "Let's see the first example. It's a letter form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYUV9trA7JWW",
    "outputId": "1b8773f1-2128-4213-d502-cdfc92a21579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE  (11314,)\n",
      "----------------------------------------\n",
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "----------------------------------------\n",
      "7 => rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(\"SHAPE \", newsgroups_train.filenames.shape)\n",
    "print(\"----------------------------------------\")\n",
    "print(newsgroups_train.data[0])\n",
    "print(\"----------------------------------------\")\n",
    "print(newsgroups_train.target[0], \"=>\", classes[newsgroups_train.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C0DhN_m-_jD"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IKZaxmMn_Bqp"
   },
   "source": [
    "Preprocessiamo ogni esempio del training. Rimuoviamo le parole \"stopwords\" e calcoliamo la rappresentazione vettoriale tf-idf.\n",
    "\n",
    "La rappresentazione della matrice è sparsa: viene mostrato un elenco di celle non nulle.\n",
    "(riga, colonna) valore\n",
    "\n",
    "Ad esempio\n",
    "(0, 59071)\t0.10043853867312116 \n",
    "\n",
    "In particolare, significano:\n",
    "(numero frase, indice della parola nel dizionario)  valore tf-idf\n",
    "\n",
    "Se provi a cercare un indice non elencato nella lista, otterrai valore 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "GH72VuMK6KI9"
   },
   "outputs": [],
   "source": [
    "# Extract features from the dataset - traduciamo le parole in vettori.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(newsgroups_train.data) # impara dal training set la matrice SPARSA tf-idf\n",
    "X_test = vectorizer.transform(newsgroups_test.data) # riutilizza la tf-idf per assegnarla alle parole nel testing set\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "# len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-xYnpvWFqDL"
   },
   "source": [
    "Let's see what's inside after the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIO985nxCpBd",
    "outputId": "68b0386a-b55c-466d-cad4-20adaee90e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 59071)\t0.10043853867312116\n",
      "  (0, 57250)\t0.1063473585616558\n",
      "  (0, 41874)\t0.224548896412017\n",
      "  (0, 49800)\t0.11869932893481257\n",
      "  (0, 46690)\t0.12504220873599214\n",
      "  (0, 73174)\t0.16142029533900565\n",
      "  (0, 99608)\t0.09418459052541318\n",
      "  (0, 84050)\t0.16329311028814825\n",
      "  (0, 37208)\t0.1434127293323407\n",
      "  (0, 62594)\t0.13037295035007848\n",
      "  (0, 87913)\t0.25808578247347563\n",
      "  (0, 54493)\t0.06961997844491917\n",
      "  (0, 23430)\t0.12937103288512333\n",
      "  (0, 77676)\t0.12197186951739486\n",
      "  (0, 81450)\t0.1461308934288897\n",
      "  (0, 24583)\t0.19644480500804062\n",
      "  (0, 16806)\t0.1407774554706102\n",
      "  (0, 83208)\t0.11339406589538423\n",
      "  (0, 76269)\t0.08978258481915573\n",
      "  (0, 34742)\t0.17300821242559045\n",
      "  (0, 24108)\t0.24723134514216435\n",
      "  (0, 25437)\t0.10548299054214269\n",
      "  (0, 11174)\t0.20599311323287353\n",
      "  (0, 35902)\t0.1266709604197344\n",
      "  (0, 9843)\t0.20797700857530224\n",
      "  (0, 55606)\t0.13822596989753821\n",
      "  (0, 57247)\t0.1352084247105906\n",
      "  (0, 84312)\t0.16368392505928514\n",
      "  (0, 34741)\t0.14847880131844235\n",
      "  (0, 31927)\t0.10526008886822914\n",
      "  (0, 80420)\t0.127069039671221\n",
      "  (0, 25717)\t0.46579831435138974\n",
      "  (0, 37256)\t0.20599311323287353\n",
      "  (0, 96879)\t0.13703598126117264\n",
      "(11314, 101322)\n",
      "11314 101322\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(X_train.shape)\n",
    "print(len(newsgroups_train.data), len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxpGgRYCIiab"
   },
   "source": [
    "Each dimension corresponds to a word in the original text. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXlffuWyGcjf",
    "outputId": "891e1dd0-4233-478b-cfaf-04a0bee9856e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mail 0.10043853867312116\n",
      "mail_________________________________ 0.0\n",
      "mail_address 0.0\n"
     ]
    }
   ],
   "source": [
    "indice_parola = 59071\n",
    "# sono in ordine alfabetico\n",
    "print(vectorizer.get_feature_names_out()[indice_parola], X_train[0, indice_parola])\n",
    "print(vectorizer.get_feature_names_out()[indice_parola+1], X_train[0, indice_parola+1])\n",
    "print(vectorizer.get_feature_names_out()[indice_parola+2], X_train[0, indice_parola+2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X_gnHpTGJ5pA"
   },
   "source": [
    "# Naive Bayes\n",
    "Con Naive Bayes assumiamo una indipendenza forte tra le feature del modello. Ogni feature è condizionatamente indipendente dall'altra data una classe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BpsrqPAkRrYl"
   },
   "source": [
    "## Multinomial NB\n",
    "Usato per feature discrete, come le parole in un testo. Conta il numero di occorrenze o il valore **tf-idf** delle parole:\n",
    "\n",
    "TODO: da rivedere\n",
    "\n",
    "$$tf_{i,j} = \\frac{n_{i,j}} {|d_j|}$$\n",
    "$$n_{i,j} = \\text{numero di volte in cui compare la parola nel documento}$$\n",
    "$$|d_j|={\\text{numero di parole del documento}}$$\n",
    "-----\n",
    "$$ idf_w = log_{10} \\frac{|D|}{|\\{d: w \\in d\\}|} $$\n",
    "$$ |D| = \\text{numero dei documenti nel corpus} $$\n",
    "$$ |\\{d: w \\in d\\}| = \\text{numero di documenti in cui la parola w appare} $$\n",
    "Non il numero di occorrenze in tutte le parole!\n",
    "----\n",
    "$$\\text{tf-idf} = tf_{i,j} \\cdot idf_i$$\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "vocabolario = [Ciao, Giacomo, Machine, Learning]\n",
    "\n",
    "tf_idf = (Ciao, 0.10), (Giacomo, 0.02), (Machine, 0.12), (Learning, 0.12)\n",
    "\n",
    "frase = \"Ciao Giacomo\"\n",
    "\n",
    "vettore_frase = [0.10, 0.02, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [('Ciao', 0.08804562952784062), ('Giacomo', 0.08804562952784062), ('Machine', 0.0), ('Learning', 0.0)]\n",
      "1 [('Ciao', 0.058697086351893746), ('Giacomo', 0.0), ('Machine', 0.15904041823988746), ('Learning', 0.058697086351893746)]\n",
      "2 [('Ciao', 0.0), ('Giacomo', 0.11739417270378749), ('Machine', 0.0), ('Learning', 0.058697086351893746)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "documento1 = \"Giacomo Ciao\"\n",
    "documento2 = \"Ciao Learning Machine\"\n",
    "documento3 = \"Giacomo Giacomo Learning\"\n",
    "corpus = [documento1, documento2, documento3]\n",
    "\n",
    "\n",
    "def numero_occorrenze_in_doc(parola, documento):\n",
    "    n_ij = 0\n",
    "    for parola_doc in documento.split(\" \"):\n",
    "        if parola_doc == parola:\n",
    "            n_ij += 1\n",
    "    return n_ij\n",
    "\n",
    "def numero_parole_documento(documento):\n",
    "    return len(documento.split(\" \"))\n",
    "\n",
    "def numero_documenti_con_parola(corpus, parola):\n",
    "    Dw = 0\n",
    "    for documento in corpus:\n",
    "        if parola in documento.split(\" \"):\n",
    "            Dw += 1\n",
    "    return Dw\n",
    "def numero_documenti_corpus(corpus):\n",
    "    return len(corpus)\n",
    "\n",
    "def term_frequency(parola, documento):\n",
    "    return numero_occorrenze_in_doc(parola, documento) / numero_parole_documento(documento)\n",
    "\n",
    "def inverse_document_frequency(parola, corpus):\n",
    "    if (numero_documenti_con_parola(corpus, parola) == 0):\n",
    "        return 0\n",
    "    return math.log(numero_documenti_corpus(corpus) / numero_documenti_con_parola(corpus, parola) , 10)\n",
    "\n",
    "def tf_idf(parola, documento, corpus):\n",
    "    return term_frequency(parola, documento) * inverse_document_frequency(parola, corpus)\n",
    "\n",
    "def vocabolario(corpus):\n",
    "    dic = set()\n",
    "    for documento in corpus:\n",
    "        for parola in documento.split(\" \"):\n",
    "            dic.add(parola)\n",
    "    return dic\n",
    "\n",
    "def vettore_tf_idf_documento(documento, corpus):\n",
    "    vett = []\n",
    "    voc = vocabolario(corpus)\n",
    "    for parola in voc:\n",
    "        tf_idf_parola_doc = tf_idf(parola, documento, corpus)\n",
    "        vett.append((parola, tf_idf_parola_doc))\n",
    "    return vett\n",
    "\n",
    "print(\"0\", vettore_tf_idf_documento(documento1, corpus))\n",
    "print(\"1\", vettore_tf_idf_documento(documento2, corpus))\n",
    "print(\"2\", vettore_tf_idf_documento(documento3, corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.62276601 0.         0.4736296  0.         0.62276601 0.        ]\n",
      " [0.         0.70710678 0.         0.         0.         0.70710678]\n",
      " [0.         0.         0.83559154 0.54935123 0.         0.        ]]\n",
      "['ciao' 'dog' 'giacomo' 'learning' 'means' 'table']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "vectorizer2 = TfidfVectorizer(stop_words='english')\n",
    "documento1 = \"Giacomo Ciao by a means\"\n",
    "documento2 = \"the dog is on the table\"\n",
    "documento3 = \"Giacomo Giacomo Learning\"\n",
    "\n",
    "\n",
    "\n",
    "x_train_prova = vectorizer.fit_transform([documento1, documento2, documento3])\n",
    "print(x_train_prova.asformat(\"array\"))\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qIaP0PWJ605",
    "outputId": "12a3b11a-a1d6-44f4-9cfa-5b062d07ba47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.44      0.19      0.27        21\n",
      "           comp.graphics       0.58      0.67      0.62        21\n",
      " comp.os.ms-windows.misc       0.65      0.50      0.57        26\n",
      "comp.sys.ibm.pc.hardware       0.70      0.76      0.73        34\n",
      "   comp.sys.mac.hardware       0.81      0.74      0.77        34\n",
      "          comp.windows.x       0.83      0.73      0.78        26\n",
      "            misc.forsale       0.74      0.77      0.76        22\n",
      "               rec.autos       0.79      0.79      0.79        28\n",
      "         rec.motorcycles       0.85      0.70      0.77        33\n",
      "      rec.sport.baseball       1.00      0.88      0.94        25\n",
      "        rec.sport.hockey       0.67      0.96      0.79        27\n",
      "               sci.crypt       0.71      0.85      0.77        20\n",
      "         sci.electronics       0.74      0.58      0.65        24\n",
      "                 sci.med       0.75      0.91      0.82        23\n",
      "               sci.space       0.79      0.82      0.81        28\n",
      "  soc.religion.christian       0.61      0.86      0.71        29\n",
      "      talk.politics.guns       0.59      0.95      0.73        21\n",
      "   talk.politics.mideast       0.82      0.78      0.80        18\n",
      "      talk.politics.misc       0.44      0.31      0.36        26\n",
      "      talk.religion.misc       0.57      0.29      0.38        14\n",
      "\n",
      "                accuracy                           0.71       500\n",
      "               macro avg       0.70      0.70      0.69       500\n",
      "            weighted avg       0.71      0.71      0.70       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the Multinomial Naive Bayes model\n",
    "MultinomialNB_model = MultinomialNB(alpha=.01) # problema di classificazione multi-classe\n",
    "\n",
    "# train\n",
    "MultinomialNB_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = MultinomialNB_model.predict(X_test[:500])\n",
    "print(classification_report(y_test[:500], y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoaUL6r3RiwR"
   },
   "source": [
    "We can extract for each class the most important features (words in our case) and print them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VaScTHgENvl_",
    "outputId": "d8c401b5-9977-47c9-91ee-9a8e51b6aa30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   alt.atheism: \tislam atheists say just religion atheism think don people god\n",
      "                 comp.graphics: \tlooking format 3d know program file files thanks image graphics\n",
      "       comp.os.ms-windows.misc: \tcard problem thanks driver drivers use files dos file windows\n",
      "      comp.sys.ibm.pc.hardware: \tmonitor disk thanks pc ide controller bus card scsi drive\n",
      "         comp.sys.mac.hardware: \tknow monitor does quadra simms thanks problem drive apple mac\n",
      "                comp.windows.x: \tusing windows x11r5 use application thanks widget server motif window\n",
      "                  misc.forsale: \tasking email sell price condition new shipping offer 00 sale\n",
      "                     rec.autos: \tdon ford new good dealer just engine like cars car\n",
      "               rec.motorcycles: \tdon just helmet riding like motorcycle ride bikes dod bike\n",
      "            rec.sport.baseball: \tbraves players pitching hit runs games game baseball team year\n",
      "              rec.sport.hockey: \tleague year nhl games season players play hockey team game\n",
      "                     sci.crypt: \tpeople use escrow nsa keys government chip clipper encryption key\n",
      "               sci.electronics: \tdon thanks voltage used know does like circuit power use\n",
      "                       sci.med: \tskepticism cadre dsl banks chastity n3jxp pitt gordon geb msg\n",
      "                     sci.space: \tjust lunar earth shuttle like moon launch orbit nasa space\n",
      "        soc.religion.christian: \tbelieve faith christian christ bible people christians church jesus god\n",
      "            talk.politics.guns: \tjust law firearms government fbi don weapons people guns gun\n",
      "         talk.politics.mideast: \tsaid arabs arab turkish people armenians armenian jews israeli israel\n",
      "            talk.politics.misc: \tknow state clinton president just think tax don government people\n",
      "            talk.religion.misc: \tthink don koresh objective christians bible people christian jesus god\n"
     ]
    }
   ],
   "source": [
    "# show the top 10 features\n",
    "def show_top10(classifier: MultinomialNB, vectorizer: TfidfVectorizer, categories: list[str]):\n",
    "  feature_names = np.asarray(vectorizer.get_feature_names_out()) # prende l'array di tutte le parole\n",
    "  for i, category in enumerate(categories):\n",
    "    top10 = np.argsort(classifier.feature_count_[i])[-10:] # prende l'elemento in posizione i tra i primi 10\n",
    "    print(\"%30s: \\t%s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "show_top10(MultinomialNB_model, vectorizer, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDf7QRM7RtvF"
   },
   "source": [
    "## Multivariate NB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "J5Szbl-KRwQK"
   },
   "source": [
    "We can train a Bernoulli model, that is the Multivariate implementation of the NB.\n",
    "Usato per le feature binarie (conta solo la presenza o l'assenza delle parole).\n",
    "\n",
    "Un documento è rappresentato da un vettore con valori in {0,1} con dimensione pari al numero di parole del dizionario.\n",
    "\n",
    "vocabolario = [Ciao, Giacomo, Machine, Learning]\n",
    "\n",
    "frase = \"Ciao Giacomo\"\n",
    "\n",
    "vettore_frase = [1, 1, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rnh6tpDzOZYi",
    "outputId": "a4732fb3-f655-42b6-a58e-ada76a8b50f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.36      0.43      0.39        21\n",
      "           comp.graphics       0.41      0.57      0.48        21\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        26\n",
      "comp.sys.ibm.pc.hardware       0.57      0.79      0.67        34\n",
      "   comp.sys.mac.hardware       0.40      0.79      0.53        34\n",
      "          comp.windows.x       0.75      0.46      0.57        26\n",
      "            misc.forsale       0.77      0.77      0.77        22\n",
      "               rec.autos       0.48      0.79      0.59        28\n",
      "         rec.motorcycles       0.50      0.73      0.59        33\n",
      "      rec.sport.baseball       0.79      0.88      0.83        25\n",
      "        rec.sport.hockey       1.00      0.85      0.92        27\n",
      "               sci.crypt       0.83      0.50      0.62        20\n",
      "         sci.electronics       0.52      0.62      0.57        24\n",
      "                 sci.med       0.84      0.70      0.76        23\n",
      "               sci.space       0.88      0.50      0.64        28\n",
      "  soc.religion.christian       0.76      0.55      0.64        29\n",
      "      talk.politics.guns       0.65      0.62      0.63        21\n",
      "   talk.politics.mideast       0.67      0.44      0.53        18\n",
      "      talk.politics.misc       0.60      0.23      0.33        26\n",
      "      talk.religion.misc       0.20      0.14      0.17        14\n",
      "\n",
      "                accuracy                           0.59       500\n",
      "               macro avg       0.60      0.57      0.56       500\n",
      "            weighted avg       0.60      0.59      0.57       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giaco/PycharmProjects/CodiceML/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/giaco/PycharmProjects/CodiceML/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/giaco/PycharmProjects/CodiceML/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# define the Multivariate Naive Bayes model\n",
    "BernoulliNB_model = BernoulliNB(alpha=.01)\n",
    "\n",
    "# train\n",
    "BernoulliNB_model.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = BernoulliNB_model.predict(X_test[:500])\n",
    "print(classification_report(y_test[:500], y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fj69fMPGe92o"
   },
   "source": [
    "And then see the most important features for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pY_XS69jR-Fa",
    "outputId": "5f046b35-8730-4411-d4f1-f21d8fabfaa5"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 88835 is out of bounds for axis 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m show_top10(BernoulliNB_model, vectorizer, classes)\n",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m, in \u001b[0;36mshow_top10\u001b[0;34m(classifier, vectorizer, categories)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i, category \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(categories):\n\u001b[1;32m      5\u001b[0m   top10 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(classifier\u001b[39m.\u001b[39mfeature_count_[i])[\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m:] \u001b[39m# prende l'elemento in posizione i tra i primi 10\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m%30s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (category, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(feature_names[top10])))\n",
      "\u001b[0;31mIndexError\u001b[0m: index 88835 is out of bounds for axis 0 with size 6"
     ]
    }
   ],
   "source": [
    "show_top10(BernoulliNB_model, vectorizer, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISE:\n",
    "* (1) Find the best _alpha_ parameter for **MultinomialNB** and **BernoulliNB** models.\n",
    "* (2) Plot the results taking _F1_ measure as reference.\n",
    "* (3) Make a comparison between **Rocchio**, **MultinomialNB** and **BernoulliNB** model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yHVrculSD9M"
   },
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.001\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.50      0.24      0.32        21\n",
      "           comp.graphics       0.54      0.62      0.58        21\n",
      " comp.os.ms-windows.misc       0.60      0.46      0.52        26\n",
      "comp.sys.ibm.pc.hardware       0.68      0.74      0.70        34\n",
      "   comp.sys.mac.hardware       0.79      0.65      0.71        34\n",
      "          comp.windows.x       0.74      0.65      0.69        26\n",
      "            misc.forsale       0.77      0.77      0.77        22\n",
      "               rec.autos       0.76      0.79      0.77        28\n",
      "         rec.motorcycles       0.88      0.64      0.74        33\n",
      "      rec.sport.baseball       1.00      0.88      0.94        25\n",
      "        rec.sport.hockey       0.67      0.96      0.79        27\n",
      "               sci.crypt       0.74      0.85      0.79        20\n",
      "         sci.electronics       0.71      0.62      0.67        24\n",
      "                 sci.med       0.69      0.87      0.77        23\n",
      "               sci.space       0.74      0.82      0.78        28\n",
      "  soc.religion.christian       0.65      0.90      0.75        29\n",
      "      talk.politics.guns       0.61      0.95      0.74        21\n",
      "   talk.politics.mideast       0.82      0.78      0.80        18\n",
      "      talk.politics.misc       0.43      0.35      0.38        26\n",
      "      talk.religion.misc       0.57      0.29      0.38        14\n",
      "\n",
      "                accuracy                           0.70       500\n",
      "               macro avg       0.69      0.69      0.68       500\n",
      "            weighted avg       0.70      0.70      0.69       500\n",
      "\n",
      "[0.32258065 0.57777778 0.52173913 0.70422535 0.70967742 0.69387755\n",
      " 0.77272727 0.77192982 0.73684211 0.93617021 0.78787879 0.79069767\n",
      " 0.66666667 0.76923077 0.77966102 0.75362319 0.74074074 0.8\n",
      " 0.38297872 0.38095238]\n",
      "Alpha 0.1\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.38      0.14      0.21        21\n",
      "           comp.graphics       0.62      0.62      0.62        21\n",
      " comp.os.ms-windows.misc       0.65      0.58      0.61        26\n",
      "comp.sys.ibm.pc.hardware       0.69      0.74      0.71        34\n",
      "   comp.sys.mac.hardware       0.83      0.74      0.78        34\n",
      "          comp.windows.x       0.86      0.73      0.79        26\n",
      "            misc.forsale       0.75      0.82      0.78        22\n",
      "               rec.autos       0.79      0.79      0.79        28\n",
      "         rec.motorcycles       0.87      0.79      0.83        33\n",
      "      rec.sport.baseball       1.00      0.92      0.96        25\n",
      "        rec.sport.hockey       0.68      1.00      0.81        27\n",
      "               sci.crypt       0.68      0.85      0.76        20\n",
      "         sci.electronics       0.76      0.54      0.63        24\n",
      "                 sci.med       0.75      0.91      0.82        23\n",
      "               sci.space       0.77      0.82      0.79        28\n",
      "  soc.religion.christian       0.50      0.86      0.63        29\n",
      "      talk.politics.guns       0.57      0.95      0.71        21\n",
      "   talk.politics.mideast       0.94      0.83      0.88        18\n",
      "      talk.politics.misc       0.58      0.27      0.37        26\n",
      "      talk.religion.misc       0.50      0.07      0.12        14\n",
      "\n",
      "                accuracy                           0.72       500\n",
      "               macro avg       0.71      0.70      0.68       500\n",
      "            weighted avg       0.72      0.72      0.70       500\n",
      "\n",
      "[0.20689655 0.61904762 0.6122449  0.71428571 0.78125    0.79166667\n",
      " 0.7826087  0.78571429 0.82539683 0.95833333 0.80597015 0.75555556\n",
      " 0.63414634 0.82352941 0.79310345 0.63291139 0.71428571 0.88235294\n",
      " 0.36842105 0.125     ]\n",
      "Alpha 1\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.67      0.10      0.17        21\n",
      "           comp.graphics       0.67      0.67      0.67        21\n",
      " comp.os.ms-windows.misc       0.62      0.58      0.60        26\n",
      "comp.sys.ibm.pc.hardware       0.67      0.76      0.71        34\n",
      "   comp.sys.mac.hardware       0.86      0.71      0.77        34\n",
      "          comp.windows.x       0.91      0.77      0.83        26\n",
      "            misc.forsale       0.74      0.77      0.76        22\n",
      "               rec.autos       0.79      0.82      0.81        28\n",
      "         rec.motorcycles       0.90      0.82      0.86        33\n",
      "      rec.sport.baseball       0.96      0.92      0.94        25\n",
      "        rec.sport.hockey       0.66      1.00      0.79        27\n",
      "               sci.crypt       0.53      0.85      0.65        20\n",
      "         sci.electronics       0.73      0.46      0.56        24\n",
      "                 sci.med       0.78      0.91      0.84        23\n",
      "               sci.space       0.82      0.82      0.82        28\n",
      "  soc.religion.christian       0.45      0.86      0.59        29\n",
      "      talk.politics.guns       0.53      0.90      0.67        21\n",
      "   talk.politics.mideast       0.88      0.78      0.82        18\n",
      "      talk.politics.misc       1.00      0.23      0.38        26\n",
      "      talk.religion.misc       0.00      0.00      0.00        14\n",
      "\n",
      "                accuracy                           0.71       500\n",
      "               macro avg       0.71      0.69      0.66       500\n",
      "            weighted avg       0.73      0.71      0.68       500\n",
      "\n",
      "[0.16666667 0.66666667 0.6        0.71232877 0.77419355 0.83333333\n",
      " 0.75555556 0.80701754 0.85714286 0.93877551 0.79411765 0.65384615\n",
      " 0.56410256 0.84       0.82142857 0.58823529 0.66666667 0.82352941\n",
      " 0.375      0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.001, 0.1, 1]\n",
    "\n",
    "for a in alpha:\n",
    "    MultinomialNB_model = MultinomialNB(alpha=a)\n",
    "    MultinomialNB_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = MultinomialNB_model.predict(X_test[:500])\n",
    "    \n",
    "    print(\"Alpha\", a)\n",
    "    print(classification_report(y_test[:500], y_pred, target_names=classes))\n",
    "    print(f1_score(y_test[:500], y_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.001\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.38      0.38      0.38        21\n",
      "           comp.graphics       0.46      0.62      0.53        21\n",
      " comp.os.ms-windows.misc       1.00      0.04      0.07        26\n",
      "comp.sys.ibm.pc.hardware       0.59      0.76      0.67        34\n",
      "   comp.sys.mac.hardware       0.40      0.74      0.52        34\n",
      "          comp.windows.x       0.71      0.58      0.64        26\n",
      "            misc.forsale       0.75      0.82      0.78        22\n",
      "               rec.autos       0.59      0.79      0.68        28\n",
      "         rec.motorcycles       0.52      0.70      0.60        33\n",
      "      rec.sport.baseball       0.78      0.84      0.81        25\n",
      "        rec.sport.hockey       1.00      0.85      0.92        27\n",
      "               sci.crypt       0.73      0.55      0.63        20\n",
      "         sci.electronics       0.54      0.62      0.58        24\n",
      "                 sci.med       0.77      0.74      0.76        23\n",
      "               sci.space       0.83      0.54      0.65        28\n",
      "  soc.religion.christian       0.71      0.59      0.64        29\n",
      "      talk.politics.guns       0.68      0.71      0.70        21\n",
      "   talk.politics.mideast       0.69      0.61      0.65        18\n",
      "      talk.politics.misc       0.62      0.31      0.41        26\n",
      "      talk.religion.misc       0.22      0.14      0.17        14\n",
      "\n",
      "                accuracy                           0.61       500\n",
      "               macro avg       0.65      0.60      0.59       500\n",
      "            weighted avg       0.66      0.61      0.60       500\n",
      "\n",
      "Alpha 0.1\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.43      0.48      0.45        21\n",
      "           comp.graphics       0.43      0.43      0.43        21\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        26\n",
      "comp.sys.ibm.pc.hardware       0.60      0.76      0.68        34\n",
      "   comp.sys.mac.hardware       0.38      0.94      0.54        34\n",
      "          comp.windows.x       0.79      0.42      0.55        26\n",
      "            misc.forsale       0.89      0.73      0.80        22\n",
      "               rec.autos       0.43      0.75      0.55        28\n",
      "         rec.motorcycles       0.40      0.82      0.54        33\n",
      "      rec.sport.baseball       0.83      0.96      0.89        25\n",
      "        rec.sport.hockey       1.00      0.85      0.92        27\n",
      "               sci.crypt       0.80      0.40      0.53        20\n",
      "         sci.electronics       0.52      0.58      0.55        24\n",
      "                 sci.med       0.75      0.52      0.62        23\n",
      "               sci.space       0.88      0.50      0.64        28\n",
      "  soc.religion.christian       0.81      0.59      0.68        29\n",
      "      talk.politics.guns       0.55      0.52      0.54        21\n",
      "   talk.politics.mideast       0.88      0.39      0.54        18\n",
      "      talk.politics.misc       0.57      0.15      0.24        26\n",
      "      talk.religion.misc       0.00      0.00      0.00        14\n",
      "\n",
      "                accuracy                           0.57       500\n",
      "               macro avg       0.60      0.54      0.53       500\n",
      "            weighted avg       0.60      0.57      0.55       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 1\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.00      0.00      0.00        21\n",
      "           comp.graphics       0.46      0.29      0.35        21\n",
      " comp.os.ms-windows.misc       0.00      0.00      0.00        26\n",
      "comp.sys.ibm.pc.hardware       0.48      0.74      0.58        34\n",
      "   comp.sys.mac.hardware       0.59      0.88      0.71        34\n",
      "          comp.windows.x       0.80      0.31      0.44        26\n",
      "            misc.forsale       1.00      0.73      0.84        22\n",
      "               rec.autos       0.41      0.79      0.54        28\n",
      "         rec.motorcycles       0.22      0.94      0.36        33\n",
      "      rec.sport.baseball       0.69      0.96      0.80        25\n",
      "        rec.sport.hockey       1.00      0.78      0.88        27\n",
      "               sci.crypt       0.60      0.30      0.40        20\n",
      "         sci.electronics       0.57      0.50      0.53        24\n",
      "                 sci.med       0.70      0.30      0.42        23\n",
      "               sci.space       0.87      0.46      0.60        28\n",
      "  soc.religion.christian       0.50      0.59      0.54        29\n",
      "      talk.politics.guns       0.50      0.24      0.32        21\n",
      "   talk.politics.mideast       0.86      0.33      0.48        18\n",
      "      talk.politics.misc       1.00      0.08      0.14        26\n",
      "      talk.religion.misc       0.00      0.00      0.00        14\n",
      "\n",
      "                accuracy                           0.50       500\n",
      "               macro avg       0.56      0.46      0.45       500\n",
      "            weighted avg       0.57      0.50      0.47       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emeli\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.001, 0.1, 1]\n",
    "\n",
    "result = []\n",
    "for a in alpha:\n",
    "    BernoulliNB_model = BernoulliNB(alpha= a)\n",
    "    BernoulliNB_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = BernoulliNB_model.predict(X_test[:500])\n",
    "    \n",
    "    print(\"Alpha\", a)\n",
    "    print(classification_report(y_test[:500], y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
